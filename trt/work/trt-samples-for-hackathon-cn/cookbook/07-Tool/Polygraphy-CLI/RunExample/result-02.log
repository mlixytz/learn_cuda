[I] RUNNING | Command: /usr/local/bin/polygraphy run modelA.onnx --trt --save-engine model-02.plan --save-timing-cache model-02.cache --save-tactics model-02-tactics.json --trt-min-shapes tensorX:[1,1,28,28] --trt-opt-shapes tensorX:[4,1,28,28] --trt-max-shapes tensorX:[16,1,28,28] --fp16 --pool-limit workspace:1G --builder-optimization-level 5 --max-aux-streams 4 --input-shapes tensorX:[4,1,28,28] --verbose
[V] Loaded Module: polygraphy | Version: 0.47.1 | Path: ['/usr/local/lib/python3.10/dist-packages/polygraphy']
[V] Loaded extension modules: []
[V] Loaded Module: tensorrt | Version: 8.6.1 | Path: ['/usr/local/lib/python3.10/dist-packages/tensorrt']
[I] Will generate inference input data according to provided TensorMetadata: {tensorX [shape=(4, 1, 28, 28)]}
[I] trt-runner-N0-08/24/23-07:55:00     | Activating and starting inference
[V] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 24, GPU 1736 (MiB)
[V] [MemUsageChange] Init builder kernel library: CPU +1444, GPU +284, now: CPU 1545, GPU 2027 (MiB)
[V] ----------------------------------------------------------------
[V] Input filename:   /wili/tensorrt-cookbook/07-Tool/Polygraphy-CLI/RunExample/modelA.onnx
[V] ONNX IR version:  0.0.8
[V] Opset version:    11
[V] Producer name:
[V] Producer version:
[V] Domain:
[V] Model version:    0
[V] Doc string:
[V] ----------------------------------------------------------------
[W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[W] Tensor DataType is determined at build time for tensors not marked as input or output.
[V]     Setting TensorRT Optimization Profiles
[V]     Input tensor: tensorX (dtype=DataType.FLOAT, shape=(-1, 1, 28, 28)) | Setting input tensor shapes to: (min=[1, 1, 28, 28], opt=[4, 1, 28, 28], max=[16, 1, 28, 28])
[I]     Configuring with profiles: [Profile().add('tensorX', min=[1, 1, 28, 28], opt=[4, 1, 28, 28], max=[16, 1, 28, 28])]
[W] Disabling tactic timing cache because algorithm selector is enabled.
[I] Building engine with configuration:
    Flags                  | [FP16, DISABLE_TIMING_CACHE]
    Engine Capability      | EngineCapability.DEFAULT
    Memory Pools           | [WORKSPACE: 1024.00 MiB, TACTIC_DRAM: 48624.94 MiB]
    Tactic Sources         | [CUBLAS, CUBLAS_LT, CUDNN, EDGE_MASK_CONVOLUTIONS, JIT_CONVOLUTIONS]
    Profiling Verbosity    | ProfilingVerbosity.DETAILED
    Preview Features       | [FASTER_DYNAMIC_SHAPES_0805, DISABLE_EXTERNAL_TACTIC_SOURCES_FOR_CORE_0805]
[V] Timing cache disabled. Turning it on will improve builder speed.
[V] Graph optimization time: 0.014467 seconds.
[V] Loaded Module: numpy | Version: 1.25.1 | Path: ['/usr/local/lib/python3.10/dist-packages/numpy']
[I] Saving tactic replay file to model-02-tactics.json
[V] [MS] Multi stream is disabled as cannot find an opportunity to leverage it
[V] Detected 1 inputs and 2 output network tensors.
[V] Total Host Persistent Memory: 32960
[V] Total Device Persistent Memory: 0
[V] Total Scratch Memory: 132096
[V] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 24 MiB, GPU 16 MiB
[V] [BlockAssignment] Started assigning block shifts. This will take 15 steps to complete.
[V] [BlockAssignment] Algorithm ShiftNTopDown took 0.093368ms to assign 4 blocks to 15 nodes requiring 1036800 bytes.
[V] Total Activation Memory: 1036288
[W] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[W] Check verbose logs for the list of affected weights.
[W] - 3 weights are affected by this issue: Detected subnormal FP16 values.
[V] Timing cache disabled. Turning it on will improve builder speed.
[V] Graph optimization time: 0.00180447 seconds.
[I] Saving tactic replay file to model-02-tactics.json
[V] [MS] Multi stream is disabled as cannot find an opportunity to leverage it
[V] Detected 1 inputs and 2 output network tensors.
[V] Total Host Persistent Memory: 8064
[V] Total Device Persistent Memory: 0
[V] Total Scratch Memory: 1605632
[V] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 24 MiB, GPU 23 MiB
[V] [BlockAssignment] Started assigning block shifts. This will take 8 steps to complete.
[V] [BlockAssignment] Algorithm ShiftNTopDown took 0.031879ms to assign 3 blocks to 8 nodes requiring 3612672 bytes.
[V] Total Activation Memory: 3612672
[V] Timing cache disabled. Turning it on will improve builder speed.
[V] Graph optimization time: 0.0112521 seconds.
[I] Saving tactic replay file to model-02-tactics.json
[V] [MS] Multi stream is disabled as cannot find an opportunity to leverage it
[V] Detected 1 inputs and 2 output network tensors.
[V] Total Host Persistent Memory: 32960
[V] Total Device Persistent Memory: 0
[V] Total Scratch Memory: 197632
[V] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 30 MiB, GPU 23 MiB
[V] [BlockAssignment] Started assigning block shifts. This will take 13 steps to complete.
[V] [BlockAssignment] Algorithm ShiftNTopDown took 0.099678ms to assign 3 blocks to 13 nodes requiring 1036288 bytes.
[V] Total Activation Memory: 1036288
[V] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +6, GPU +7, now: CPU 6, GPU 7 (MiB)
[I] Finished engine building in 16.696 seconds
[V] Loaded Module: fcntl
[I] Saving tactic timing cache to model-02.cache
[V] Loaded engine size: 6 MiB
[V] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +6, now: CPU 0, GPU 6 (MiB)
[V] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +1, now: CPU 0, GPU 7 (MiB)
[V] Found candidate CUDA libraries: ['/usr/local/cuda/lib64/libcudart.so.12.1.105', '/usr/local/cuda/lib64/libcudart.so', '/usr/local/cuda/lib64/libcudart.so.12']
[V] Loading inputs from data loader
[V] Generating data using numpy seed: 1
[V] Input tensor: tensorX | Generating input data in range: [0.0, 1.0]
[I] trt-runner-N0-08/24/23-07:55:00
    ---- Inference Input(s) ----
    {tensorX [dtype=float32, shape=(4, 1, 28, 28)]}
[V] trt-runner-N0-08/24/23-07:55:00     | Input metadata is: {tensorX [dtype=float32, shape=(-1, 1, 28, 28)]}
[I] trt-runner-N0-08/24/23-07:55:00
    ---- Inference Output(s) ----
    {A-V-12-Add [dtype=float32, shape=(4, 10)],
     A-V-14-ArgMax [dtype=int32, shape=(4,)]}
[I] trt-runner-N0-08/24/23-07:55:00     | Completed 1 iteration(s) in 0.5982 ms | Average inference time: 0.5982 ms.
[V] Successfully ran: ['trt-runner-N0-08/24/23-07:55:00']
[I] PASSED | Runtime: 20.754s | Command: /usr/local/bin/polygraphy run modelA.onnx --trt --save-engine model-02.plan --save-timing-cache model-02.cache --save-tactics model-02-tactics.json --trt-min-shapes tensorX:[1,1,28,28] --trt-opt-shapes tensorX:[4,1,28,28] --trt-max-shapes tensorX:[16,1,28,28] --fp16 --pool-limit workspace:1G --builder-optimization-level 5 --max-aux-streams 4 --input-shapes tensorX:[4,1,28,28] --verbose
